{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T23:42:14.350677400Z",
     "start_time": "2023-11-20T23:42:13.539817600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_folder, csv_file, transform=None):\n",
    "        self.data_folder = data_folder\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.data_folder, self.df.iloc[idx]['original_title'])\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "\n",
    "        target = self.df.iloc[idx]['target_column']  # Replace 'target_column' with the actual column name in your CSV\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, target"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T22:52:33.561740100Z",
     "start_time": "2023-11-20T22:52:33.543189900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Resize (transforms.Resize((192, 192))):\n",
    "\n",
    "Objective: Standardizes the size of the image.\n",
    "How: Resizes the image to a fixed size of 192x192 pixels.\n",
    "Random Horizontal Flip (transforms.RandomHorizontalFlip()):\n",
    "\n",
    "Objective: Enhances the model's ability to recognize objects regardless of their orientation.\n",
    "How: Flips the image horizontally with a 50% probability.\n",
    "Random Vertical Flip (transforms.RandomVerticalFlip()):\n",
    "\n",
    "Objective: Adds more variety to the training data by flipping images vertically.\n",
    "How: Flips the image vertically with a 50% probability.\n",
    "Random Rotation (transforms.RandomRotation(degrees=20)):\n",
    "\n",
    "Objective: Enhances rotation invariance of the model.\n",
    "How: Applies a random rotation to the image, up to 20 degrees.\n",
    "Color Jitter (transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2)):\n",
    "\n",
    "Objective: Simulates different lighting conditions and color variations.\n",
    "How: Randomly adjusts brightness, contrast, saturation, and hue.\n",
    "Gaussian Blur (transforms.GaussianBlur(kernel_size=3)):\n",
    "\n",
    "Objective: Simulates the effect of dirt or haze.\n",
    "How: Applies random Gaussian blur to the image. Adjust the kernel size as needed.\n",
    "Random Noise (transforms.RandomApply([transforms.Lambda(lambda x: x + 0.01 * torch.randn_like(x))], p=0.5)):\n",
    "\n",
    "Objective: Simulates environmental conditions and adds robustness.\n",
    "How: Introduces random noise to the image with a 50% probability.\n",
    "Random Grayscale (transforms.RandomGrayscale(p=0.1)):\n",
    "\n",
    "Objective: Accounts for potential variations in color.\n",
    "How: Converts the image to grayscale with a 10% probability.\n",
    "To Tensor (transforms.ToTensor()):\n",
    "\n",
    "Objective: Converts the image to a PyTorch tensor.\n",
    "How: Transforms the image data into a format suitable for deep learning.\n",
    "Normalize (transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])):\n",
    "\n",
    "Objective: Ensures consistent and standardized input data.\n",
    "How: Normalizes the pixel values of the tensor to have a mean of 0.5 and a standard deviation of 0.5 for each channel."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((192, 192)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(degrees=20),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    transforms.GaussianBlur(kernel_size=3),  # You can adjust the kernel size\n",
    "    transforms.RandomApply([transforms.Lambda(lambda x: x + 0.01 * torch.randn_like(x))], p=0.5),  # Add random noise\n",
    "    transforms.RandomGrayscale(p=0.1),  # Convert to grayscale with a probability of 0.1\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T23:38:30.058493400Z",
     "start_time": "2023-11-20T23:38:30.050007200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "data_folder = 'SolarPanelSoilingImageDataset\\Solar_Panel_Soiling_Image_dataset\\Pytorch_data/'\n",
    "csv_file = 'filtered_data.csv'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T23:41:31.886266300Z",
     "start_time": "2023-11-20T23:41:31.850224200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Create an instance of the CustomDataset with the preprocessing transform\n",
    "custom_dataset = CustomDataset(data_folder, csv_file, transform=transform)\n",
    "\n",
    "# Create a DataLoader to load batches of data\n",
    "batch_size = 64\n",
    "data_loader = DataLoader(custom_dataset, batch_size=batch_size, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T23:41:45.478962400Z",
     "start_time": "2023-11-20T23:41:45.451207500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'target_column'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32mC:\\Python\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3803\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3802\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3803\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3804\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32mC:\\Python\\Lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mC:\\Python\\Lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'target_column'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [13], line 20\u001B[0m\n\u001B[0;32m     17\u001B[0m     plt\u001B[38;5;241m.\u001B[39mshow()\n\u001B[0;32m     19\u001B[0m \u001B[38;5;66;03m# Get a batch of data\u001B[39;00m\n\u001B[1;32m---> 20\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch_images, batch_labels \u001B[38;5;129;01min\u001B[39;00m data_loader:\n\u001B[0;32m     21\u001B[0m     show_images(batch_images, batch_labels)\n\u001B[0;32m     22\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32mC:\\Python\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    627\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    628\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    629\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 630\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    631\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    632\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    633\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32mC:\\Python\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    672\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    673\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 674\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    675\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    676\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32mC:\\Python\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     49\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 51\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43midx\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mpossibly_batched_index\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32mC:\\Python\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     49\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 51\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "Cell \u001B[1;32mIn [6], line 14\u001B[0m, in \u001B[0;36mCustomDataset.__getitem__\u001B[1;34m(self, idx)\u001B[0m\n\u001B[0;32m     11\u001B[0m img_name \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata_folder, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdf\u001B[38;5;241m.\u001B[39miloc[idx][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124moriginal_title\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m     12\u001B[0m image \u001B[38;5;241m=\u001B[39m Image\u001B[38;5;241m.\u001B[39mopen(img_name)\u001B[38;5;241m.\u001B[39mconvert(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRGB\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m---> 14\u001B[0m target \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miloc\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtarget_column\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m  \u001B[38;5;66;03m# Replace 'target_column' with the actual column name in your CSV\u001B[39;00m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform:\n\u001B[0;32m     17\u001B[0m     image \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform(image)\n",
      "File \u001B[1;32mC:\\Python\\Lib\\site-packages\\pandas\\core\\series.py:981\u001B[0m, in \u001B[0;36mSeries.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m    978\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_values[key]\n\u001B[0;32m    980\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m key_is_scalar:\n\u001B[1;32m--> 981\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_value\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    983\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_hashable(key):\n\u001B[0;32m    984\u001B[0m     \u001B[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001B[39;00m\n\u001B[0;32m    985\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    986\u001B[0m         \u001B[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001B[39;00m\n",
      "File \u001B[1;32mC:\\Python\\Lib\\site-packages\\pandas\\core\\series.py:1089\u001B[0m, in \u001B[0;36mSeries._get_value\u001B[1;34m(self, label, takeable)\u001B[0m\n\u001B[0;32m   1086\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_values[label]\n\u001B[0;32m   1088\u001B[0m \u001B[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001B[39;00m\n\u001B[1;32m-> 1089\u001B[0m loc \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlabel\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1090\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindex\u001B[38;5;241m.\u001B[39m_get_values_for_loc(\u001B[38;5;28mself\u001B[39m, loc, label)\n",
      "File \u001B[1;32mC:\\Python\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3803\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[0;32m   3804\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m-> 3805\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m   3806\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m   3807\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[0;32m   3808\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[0;32m   3809\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[0;32m   3810\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[1;31mKeyError\u001B[0m: 'target_column'"
     ]
    }
   ],
   "source": [
    "def show_images(images, labels):\n",
    "    fig, axs = plt.subplots(4, 8, figsize=(15, 8))\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    for i in range(len(axs)):\n",
    "        image, label = images[i], labels[i]\n",
    "        image = image.numpy().transpose((1, 2, 0))\n",
    "        mean = np.array([0.5, 0.5, 0.5])\n",
    "        std = np.array([0.5, 0.5, 0.5])\n",
    "        image = std * image + mean\n",
    "        image = np.clip(image, 0, 1)\n",
    "\n",
    "        axs[i].imshow(image)\n",
    "        axs[i].set_title(f\"Label: {label}\")\n",
    "        axs[i].axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Get a batch of data\n",
    "for batch_images, batch_labels in data_loader:\n",
    "    show_images(batch_images, batch_labels)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T23:42:20.417149900Z",
     "start_time": "2023-11-20T23:42:20.091219400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "'''\n",
    "class ImageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_folder, csv_file, transform=None):\n",
    "        self.image_folder = image_folder\n",
    "        self.csv_file = csv_file\n",
    "        self.transform = transform\n",
    "\n",
    "        # Read CSV file into a pandas DataFrame\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "\n",
    "        # Create a dictionary to map image filenames to their corresponding targets\n",
    "        self.image_to_target = {}\n",
    "        for index, row in self.df.iterrows():\n",
    "            image_filename = row['original_title'] + '.jpg'\n",
    "            target = row['original_title']\n",
    "            self.image_to_target[image_filename] = target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_to_target)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Get image filename and target for the current index\n",
    "        image_filename, target = list(self.image_to_target.items())[index]\n",
    "        image_path = os.path.join(self.image_folder, image_filename)\n",
    "\n",
    "        # Load image\n",
    "        image = Image.open(image_path)\n",
    "\n",
    "        # Apply transformation if provided\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Convert image to tensor\n",
    "        image = torch.from_numpy(image.numpy().transpose(2, 0, 1)).float()\n",
    "\n",
    "        # Return image tensor and target\n",
    "        return image, target\n",
    "\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T22:50:41.123485Z",
     "start_time": "2023-11-20T22:50:41.115474500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "image_folder = 'SolarPanelSoilingImageDataset\\Solar_Panel_Soiling_Image_dataset\\Pytorch_data/'\n",
    "csv_file = 'filtered_data.csv'\n",
    "dataset = ImageDataset(image_folder, csv_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T22:50:43.337979300Z",
     "start_time": "2023-11-20T22:50:42.937416500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\tfrod\\\\Desktop\\\\CV Project\\\\SolarPanelSoilingImageDataset\\\\Solar_Panel_Soiling_Image_dataset\\\\Pytorch_data\\\\6'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [7], line 43\u001B[0m\n\u001B[0;32m     40\u001B[0m custom_dataset \u001B[38;5;241m=\u001B[39m CustomDataset(csv_file\u001B[38;5;241m=\u001B[39mcsv_file, root_dir\u001B[38;5;241m=\u001B[39mroot_dir)\n\u001B[0;32m     42\u001B[0m \u001B[38;5;66;03m# Access an example from the dataset\u001B[39;00m\n\u001B[1;32m---> 43\u001B[0m sample_image, sample_target \u001B[38;5;241m=\u001B[39m \u001B[43mcustom_dataset\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[0;32m     44\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSample Image Shape: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00msample_image\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     45\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSample Target: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00msample_target\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "Cell \u001B[1;32mIn [7], line 19\u001B[0m, in \u001B[0;36mCustomDataset.__getitem__\u001B[1;34m(self, idx)\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, idx):\n\u001B[0;32m     18\u001B[0m     img_name \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mroot_dir, \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdf\u001B[38;5;241m.\u001B[39miloc[idx, \u001B[38;5;241m0\u001B[39m]))\n\u001B[1;32m---> 19\u001B[0m     image \u001B[38;5;241m=\u001B[39m \u001B[43mImage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     21\u001B[0m     \u001B[38;5;66;03m# Assuming the target column is named 'loss_percentage'\u001B[39;00m\n\u001B[0;32m     22\u001B[0m     target \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdf\u001B[38;5;241m.\u001B[39miloc[idx, \u001B[38;5;241m1\u001B[39m], dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat32)\n",
      "File \u001B[1;32mC:\\Python\\Lib\\site-packages\\PIL\\Image.py:3131\u001B[0m, in \u001B[0;36mopen\u001B[1;34m(fp, mode, formats)\u001B[0m\n\u001B[0;32m   3128\u001B[0m     filename \u001B[38;5;241m=\u001B[39m fp\n\u001B[0;32m   3130\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m filename:\n\u001B[1;32m-> 3131\u001B[0m     fp \u001B[38;5;241m=\u001B[39m \u001B[43mbuiltins\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3132\u001B[0m     exclusive_fp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m   3134\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\tfrod\\\\Desktop\\\\CV Project\\\\SolarPanelSoilingImageDataset\\\\Solar_Panel_Soiling_Image_dataset\\\\Pytorch_data\\\\6'"
     ]
    }
   ],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the CSV file with target values.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, str(self.df.iloc[idx, 0]))\n",
    "        image = Image.open(img_name)\n",
    "\n",
    "        # Assuming the target column is named 'loss_percentage'\n",
    "        target = torch.tensor(self.df.iloc[idx, 1], dtype=torch.float32)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, target\n",
    "\n",
    "# Specify the paths\n",
    "csv_file = 'filtered_data.csv'\n",
    "root_dir = 'SolarPanelSoilingImageDataset\\\\Solar_Panel_Soiling_Image_dataset\\\\Pytorch_data'\n",
    "\n",
    "# Define a transformation (resize, normalize, etc.) if needed\n",
    "#transform = transforms.Compose([\n",
    "#    transforms.Resize((224, 224)),\n",
    "#    transforms.ToTensor(),\n",
    "#])\n",
    "\n",
    "# Create an instance of the CustomDataset\n",
    "custom_dataset = CustomDataset(csv_file=csv_file, root_dir=root_dir)\n",
    "\n",
    "# Access an example from the dataset\n",
    "sample_image, sample_target = custom_dataset[0]\n",
    "print(f'Sample Image Shape: {sample_image.shape}')\n",
    "print(f'Sample Target: {sample_target}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T18:30:53.256699200Z",
     "start_time": "2023-11-20T18:30:53.201897600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
