{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "EVZbTfBslbWa"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchmetrics\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.utils.data as data\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available with 1 device(s).\n",
      "Current GPU: NVIDIA GeForce GTX 1660\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    # Get the number of available GPUs\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(f\"GPU is available with {num_gpus} device(s).\")\n",
    "    \n",
    "    # Get the name of the current GPU\n",
    "    current_gpu = torch.cuda.get_device_name(0)  # Assuming the first GPU is used\n",
    "    print(f\"Current GPU: {current_gpu}\")\n",
    "else:\n",
    "    print(\"GPU is not available. Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # Use the first available GPU\n",
    "else:\n",
    "    device = torch.device(\"cpu\")  # If no GPU is available, use CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = os.getcwd()\n",
    "models_dir = current_directory + '/models'\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "df = pd.read_csv('filtered_data.csv')\n",
    "images_dir = '/run/media/victor/victor/cv_project/SolarPanelSoilingImageDataset/Solar_Panel_Soiling_Image_dataset/PanelImages'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SolarPanelDataset(data.Dataset):\n",
    "    #data_dir: The directory containing the image files\n",
    "    #image_shape: The shape of the images (height, width, channels)\n",
    "    #augmentation_copies: The number of copies of each image to create for data augmentation\n",
    "    def __init__(self, df, data_dir, image_shape=(3, 192, 192), augmentation_copies=1):\n",
    "        self.copies = 1 + augmentation_copies\n",
    "        self.image_shape = image_shape\n",
    "        self.df = df #df: A pandas DataFrame containing the image filenames and labels\n",
    "        self.labels = []\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((self.image_shape[1], self.image_shape[2])),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "        self.augmentation_transform = self.make_augmentation_transform()\n",
    "        self.dataset_size = len(df)\n",
    "        self.images = torch.zeros((self.dataset_size, *self.image_shape), dtype=torch.float32)\n",
    "\n",
    "        for i, img_name in enumerate(self.df['original_title']):\n",
    "            img_path = os.path.join(data_dir, img_name)\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            self.images[i] = image\n",
    "            label = df.iloc[i]['loss_percentage']\n",
    "            self.labels.append(label)  # Add corresponding label here\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)*self.copies\n",
    "\n",
    "    def make_augmentation_transform(self):\n",
    "        return transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(p=0.2),\n",
    "            transforms.RandomVerticalFlip(p=0.2),\n",
    "            transforms.RandomRotation(degrees=20),\n",
    "            transforms.ColorJitter(brightness=(0.8, 1.2), contrast=(0.8, 1.2), saturation=(0.8, 1.2), hue=(-0.1, 0.1)),\n",
    "            transforms.GaussianBlur(kernel_size=3),  # You can adjust the kernel size\n",
    "            transforms.RandomApply([transforms.Lambda(lambda x: x + 0.01 * torch.randn_like(x))], p=0.2),\n",
    "        ])\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        if (idx >= len(self.images) ):\n",
    "            image = self.images[idx % len(self.images)]\n",
    "            label = self.labels[idx % len(self.labels)]\n",
    "            return self.augmentation_transform(image), torch.tensor(label, dtype=torch.float32)\n",
    "            \n",
    "            \n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        return image, torch.tensor(label, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regression_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(32400, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RegressionCNN, self).__init__()\n",
    "\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # Batch normalization for improved training stability\n",
    "        self.batch_norm1 = nn.BatchNorm2d(64)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(128)\n",
    "        self.batch_norm3 = nn.BatchNorm2d(256)\n",
    "\n",
    "        # Max pooling layer\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "        # Dropout for regularization\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(256 * 48 * 48, 512)\n",
    "        self.fc2 = nn.Linear(512, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.leaky_relu(self.batch_norm1(self.conv1(x))))\n",
    "        x = self.pool(F.leaky_relu(self.batch_norm2(self.conv2(x))))\n",
    "        x = self.pool(F.leaky_relu(self.batch_norm3(self.conv3(x))))\n",
    "\n",
    "        x = x.view(-1, 256 * 48 * 48)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to save the model\n",
    "def saveModel(model:nn.Module, path):\n",
    "    torch.save(model.state_dict(), path)\n",
    "\n",
    "# Training function. We simply have to loop over our data iterator and feed the inputs to the network and optimize.\n",
    "def train(model: torch.nn.Module,\n",
    "          dataloader: torch.utils.data.DataLoader,\n",
    "          loss_fn: torch.nn.Module,\n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          metric: torchmetrics.Metric,\n",
    "          device: torch.device,\n",
    "          num_epochs,\n",
    "          path_model,\n",
    "          report: pd.DataFrame,\n",
    "          verbatim):\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    metric.to(device)\n",
    "    best_accuracy = 0.0\n",
    "    best_loss = 0.0\n",
    "    best_epoch = 0\n",
    "    metric_algorithm = metric.__class__.__name__\n",
    "    loss_algorithm = loss_fn.__class__.__name__\n",
    "    best_metric = 100\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "        train_acc = 0.0\n",
    "        train_loss = 0.0\n",
    "        for ibatch, (images, labels) in enumerate(dataloader, 0):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(images)\n",
    "            y_pred = y_pred.squeeze(dim=1) # Output is [Batch size, 1], but we want [Batch size]\n",
    "            loss = loss_fn(y_pred, labels)\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            metric(y_pred, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            print(loss)\n",
    "            # Calculate and accumulate accuracy metric across all batches\n",
    "            #y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
    "            #train_acc += (y_pred_class == labels).sum().item()/len(y_pred)\n",
    "\n",
    "        # Adjust metrics to get average loss and accuracy per batch\n",
    "        train_loss = train_loss / len(dataloader)\n",
    "\n",
    "        # we want to save the model if the accuracy is the best\n",
    "\n",
    "        path = \"./myModel_\" +str(epoch)+ \".pth\"\n",
    "        #saveModel(model, path = path)\n",
    "\n",
    "        batch_metric = metric.compute()\n",
    "        report_line = {'epoch': epoch,\n",
    "                       'batch_loss': train_loss,\n",
    "                       'metric_algorithm': metric_algorithm,\n",
    "                       'batch_metric': batch_metric.item(),\n",
    "                       'loss_algorithm': loss_algorithm\n",
    "                      }\n",
    "        report = pd.concat([report, pd.DataFrame([report_line])], ignore_index=True)\n",
    "\n",
    "        if batch_metric < best_metric:\n",
    "            path = str(path_model + '/bestModel.pth')\n",
    "            saveModel(model, path = path)\n",
    "            best_loss = train_loss\n",
    "            best_metric = batch_metric\n",
    "            best_epoch = epoch\n",
    "            if verbatim:\n",
    "              print('Best Epoch #', epoch,' Loss=', best_loss, \" Accu=\", best_accuracy )\n",
    "\n",
    "    return best_loss, best_accuracy, best_epoch, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1987, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1058, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1087, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1263, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1268, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0741, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1042, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0934, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1184, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1150, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0913, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0759, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0637, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0718, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0924, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0861, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1056, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0789, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0913, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0573, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1077, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0752, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0787, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0636, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0667, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0790, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0794, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0587, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0795, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0790, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0914, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0820, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0814, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0694, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0792, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0798, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0889, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0850, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0524, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0796, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0971, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0620, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0744, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0771, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0700, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0592, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1059, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0676, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0599, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0802, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0566, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0708, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0805, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0649, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0505, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0638, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0774, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0722, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0699, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0697, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0574, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0979, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0666, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0509, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0902, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0600, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0690, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0650, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0604, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0764, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0720, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0741, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0595, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0771, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0787, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0545, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0536, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0616, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0781, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0933, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0672, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0526, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0609, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0611, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0567, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0624, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0591, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0538, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0574, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0679, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0624, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0628, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0725, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0597, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0549, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0540, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0754, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0666, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0636, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0512, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0503, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0616, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0558, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0610, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0501, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0670, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0470, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0469, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0512, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0635, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0613, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0513, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0484, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0615, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0639, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0800, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0590, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0490, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0678, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0444, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0481, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0289, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0309, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0616, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0872, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0754, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0473, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0448, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0698, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0592, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0523, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0461, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0774, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0480, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0804, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0576, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0521, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0326, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0427, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0585, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0574, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0421, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0482, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0507, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0367, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0515, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0573, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0359, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0618, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0375, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0456, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0583, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0373, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0492, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0620, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0376, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0356, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0372, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0426, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0256, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0381, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0385, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0436, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0529, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0452, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0421, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0388, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0493, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0380, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0426, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0391, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0569, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0486, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0735, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0538, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0511, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0565, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0446, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0404, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0468, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0524, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0452, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0384, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0454, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0604, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0354, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0288, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0418, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0425, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0429, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0492, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0259, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0318, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0504, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0477, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0512, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0582, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0413, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0392, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0365, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0239, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0527, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0410, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0313, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0575, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0310, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0493, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0361, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0370, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0270, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0392, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0418, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0511, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0268, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0396, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0421, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0386, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0411, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0366, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0359, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0439, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0393, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0621, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0365, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0337, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0338, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0286, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0552, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0295, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0337, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0418, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0521, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0294, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0315, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0499, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0343, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0313, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0255, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0413, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0351, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0290, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0234, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0372, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0233, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0283, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0258, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0370, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0476, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0428, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0418, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0425, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0233, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0356, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0329, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0274, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0299, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0279, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0347, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0360, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0350, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0351, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0335, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0489, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0314, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0316, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0283, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0252, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0302, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0389, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0286, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0277, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0364, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0242, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0395, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0413, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0371, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0255, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0331, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0319, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0422, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0428, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0313, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0227, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0310, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0303, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0361, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0539, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0284, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0242, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0260, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0260, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0324, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0269, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0449, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0272, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0355, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0223, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0322, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0298, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0278, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0320, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0305, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0283, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0262, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0277, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0318, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0236, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0298, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = Regression_CNN()\n",
    "metric = torchmetrics.MeanAbsolutePercentageError()\n",
    "dataset = SolarPanelDataset(train_df.sample(1000), images_dir)\n",
    "train_dataloader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "loss_fn = torch.nn.MSELoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.005, momentum=0.9)\n",
    "num_epochs = 10\n",
    "path_model = models_dir + f'/{model.__class__.__name__}_{loss_fn.__class__.__name__}'\n",
    "os.makedirs(path_model, exist_ok=True)\n",
    "report = pd.DataFrame()\n",
    "_, _, _, report = train(model, train_dataloader, loss_fn, optimizer, metric, device, num_epochs, path_model, report, verbatim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>batch_loss</th>\n",
       "      <th>metric_algorithm</th>\n",
       "      <th>batch_metric</th>\n",
       "      <th>loss_algorithm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.091464</td>\n",
       "      <td>MeanAbsolutePercentageError</td>\n",
       "      <td>117.332161</td>\n",
       "      <td>MSELoss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.072445</td>\n",
       "      <td>MeanAbsolutePercentageError</td>\n",
       "      <td>165.558563</td>\n",
       "      <td>MSELoss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.065278</td>\n",
       "      <td>MeanAbsolutePercentageError</td>\n",
       "      <td>176.601837</td>\n",
       "      <td>MSELoss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.056931</td>\n",
       "      <td>MeanAbsolutePercentageError</td>\n",
       "      <td>171.393692</td>\n",
       "      <td>MSELoss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.049591</td>\n",
       "      <td>MeanAbsolutePercentageError</td>\n",
       "      <td>157.379044</td>\n",
       "      <td>MSELoss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.045264</td>\n",
       "      <td>MeanAbsolutePercentageError</td>\n",
       "      <td>151.991791</td>\n",
       "      <td>MSELoss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.041277</td>\n",
       "      <td>MeanAbsolutePercentageError</td>\n",
       "      <td>152.175613</td>\n",
       "      <td>MSELoss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.035795</td>\n",
       "      <td>MeanAbsolutePercentageError</td>\n",
       "      <td>146.323624</td>\n",
       "      <td>MSELoss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.032700</td>\n",
       "      <td>MeanAbsolutePercentageError</td>\n",
       "      <td>144.199280</td>\n",
       "      <td>MSELoss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.029662</td>\n",
       "      <td>MeanAbsolutePercentageError</td>\n",
       "      <td>145.461533</td>\n",
       "      <td>MSELoss</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  batch_loss             metric_algorithm  batch_metric loss_algorithm\n",
       "0      0    0.091464  MeanAbsolutePercentageError    117.332161        MSELoss\n",
       "1      1    0.072445  MeanAbsolutePercentageError    165.558563        MSELoss\n",
       "2      2    0.065278  MeanAbsolutePercentageError    176.601837        MSELoss\n",
       "3      3    0.056931  MeanAbsolutePercentageError    171.393692        MSELoss\n",
       "4      4    0.049591  MeanAbsolutePercentageError    157.379044        MSELoss\n",
       "5      5    0.045264  MeanAbsolutePercentageError    151.991791        MSELoss\n",
       "6      6    0.041277  MeanAbsolutePercentageError    152.175613        MSELoss\n",
       "7      7    0.035795  MeanAbsolutePercentageError    146.323624        MSELoss\n",
       "8      8    0.032700  MeanAbsolutePercentageError    144.199280        MSELoss\n",
       "9      9    0.029662  MeanAbsolutePercentageError    145.461533        MSELoss"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to test the model with the test dataset and print the accuracy for the test images\n",
    "def test(model: torch.nn.Module,\n",
    "         dataloader: torch.utils.data.DataLoader,\n",
    "         loss_fn: torch.nn.Module,\n",
    "         metric: torchmetrics.Metric,\n",
    "         device: torch.device,\n",
    "         verbatim = True):\n",
    "\n",
    "    model.eval()\n",
    "    metric = metric.to(device)\n",
    "\n",
    "    # Setup test loss and test accuracy values\n",
    "    test_loss = 0\n",
    "    test_metric = 100\n",
    "    pred_labels = []\n",
    "    label_list = []\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            y_pred = model(images)\n",
    "            y_pred = y_pred.squeeze(dim=1) # Output is [Batch size, 1], but we want [Batch size]\n",
    "            pred_labels+=y_pred.tolist()\n",
    "            label_list += labels.tolist()\n",
    "            \n",
    "            loss = loss_fn(y_pred, labels)\n",
    "            test_loss += loss.item()\n",
    "            metric.update(y_pred, labels)\n",
    "\n",
    "    eval_df = pd.DataFrame({'labels': label_list, 'predictions': pred_labels})\n",
    "    # Adjust metrics to get average loss and accuracy per batch\n",
    "    test_loss = test_loss / len(dataloader)\n",
    "    test_metric = metric.compute()\n",
    "\n",
    "    if verbatim:\n",
    "      print(\"Loss =\", test_loss, f'  Metric ({metric.__class__.__name__})=', test_metric.item())\n",
    "    return pred_labels, test_loss, test_metric, eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.044260744292002455   Metric (MeanAbsolutePercentageError)= 523.5400390625\n"
     ]
    }
   ],
   "source": [
    "metric = torchmetrics.MeanAbsolutePercentageError()\n",
    "test_dataset = SolarPanelDataset(test_df.sample(200), images_dir)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "_, _, _, eval_df = test(model, test_dataloader, loss_fn, metric, device, verbatim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.770407</td>\n",
       "      <td>0.164719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.055255</td>\n",
       "      <td>0.137564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.040302</td>\n",
       "      <td>0.114739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.397067</td>\n",
       "      <td>0.128074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.016211</td>\n",
       "      <td>0.116730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0.572883</td>\n",
       "      <td>0.129467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0.638548</td>\n",
       "      <td>0.635345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0.145178</td>\n",
       "      <td>0.120767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0.075883</td>\n",
       "      <td>0.170131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0.190312</td>\n",
       "      <td>0.257816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       labels  predictions\n",
       "0    0.770407     0.164719\n",
       "1    0.055255     0.137564\n",
       "2    0.040302     0.114739\n",
       "3    0.397067     0.128074\n",
       "4    0.016211     0.116730\n",
       "..        ...          ...\n",
       "395  0.572883     0.129467\n",
       "396  0.638548     0.635345\n",
       "397  0.145178     0.120767\n",
       "398  0.075883     0.170131\n",
       "399  0.190312     0.257816\n",
       "\n",
       "[400 rows x 2 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "id": "8rpJuShwm6wk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "iIKHssGLogv5"
   },
   "outputs": [],
   "source": [
    "\n",
    "def tensor_to_image(tensor):\n",
    "\n",
    "    \"\"\"\n",
    "    Converts a tensor to an image.\n",
    "\n",
    "    Args:\n",
    "        tensor: A tensor of shape (C, H, W).\n",
    "\n",
    "    Returns:\n",
    "        An image.\n",
    "    \"\"\"\n",
    "\n",
    "    image = tensor.cpu().detach().numpy()\n",
    "    image = image.transpose(1, 2, 0)  # Convert from (C, H, W) to (H, W, C)\n",
    "    image = (image * 255).astype('uint8')  # Convert pixel values from [0, 1] to [0, 255]\n",
    "\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1vYUgNJypt8t"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
