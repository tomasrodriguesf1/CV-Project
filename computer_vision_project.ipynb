{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "EVZbTfBslbWa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/victor/codes/python_env/virtualenv/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/victor/codes/python_env/virtualenv/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchmetrics\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.utils.data as data\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available with 1 device(s).\n",
      "Current GPU: NVIDIA GeForce GTX 1660\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    # Get the number of available GPUs\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(f\"GPU is available with {num_gpus} device(s).\")\n",
    "    \n",
    "    # Get the name of the current GPU\n",
    "    current_gpu = torch.cuda.get_device_name(0)  # Assuming the first GPU is used\n",
    "    print(f\"Current GPU: {current_gpu}\")\n",
    "else:\n",
    "    print(\"GPU is not available. Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # Use the first available GPU\n",
    "else:\n",
    "    device = torch.device(\"cpu\")  # If no GPU is available, use CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = os.getcwd()\n",
    "models_dir = current_directory + '/models'\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "df = pd.read_csv('filtered_data.csv')\n",
    "images_dir = '/run/media/victor/victor/cv_project/SolarPanelSoilingImageDataset/Solar_Panel_Soiling_Image_dataset/PanelImages'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T15:58:57.402078300Z",
     "start_time": "2023-11-22T15:58:57.190041400Z"
    }
   },
   "outputs": [],
   "source": [
    "class SolarPanelDataset(data.Dataset):\n",
    "    #data_dir: The directory containing the image files\n",
    "    #image_shape: The shape of the images (height, width, channels)\n",
    "    #augmentation_copies: The number of copies of each image to create for data augmentation\n",
    "    def __init__(self, df, data_dir, image_shape=(3, 192, 192), training=False):\n",
    "        self.copies = 1\n",
    "        if training == True:\n",
    "            self.copies = 2\n",
    "            \n",
    "        self.image_shape = image_shape\n",
    "        self.df = df #df: A pandas DataFrame containing the image filenames and labels\n",
    "        self.labels = []\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((self.image_shape[1], self.image_shape[2])),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "        self.augmentation_transform = self.make_augmentation_transform()\n",
    "        self.dataset_size = len(df)\n",
    "        self.images = torch.zeros((self.dataset_size, *self.image_shape), dtype=torch.uint8)\n",
    "\n",
    "        for i, img_name in enumerate(self.df['original_title']):\n",
    "            img_path = os.path.join(data_dir, img_name)\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "                image = image.mul(255).byte()\n",
    "            self.images[i] = image\n",
    "            label = df.iloc[i]['loss_percentage']\n",
    "            self.labels.append(label)  # Add corresponding label here\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)*self.copies\n",
    "\n",
    "    def make_augmentation_transform(self):\n",
    "        return transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(p=0.2),\n",
    "            transforms.RandomVerticalFlip(p=0.2),\n",
    "            transforms.RandomRotation(degrees=20),\n",
    "            transforms.ColorJitter(brightness=(0.8, 1.2), contrast=(0.8, 1.2), saturation=(0.8, 1.2), hue=(-0.1, 0.1)),\n",
    "            transforms.GaussianBlur(kernel_size=3),  # You can adjust the kernel size\n",
    "            transforms.RandomApply([transforms.Lambda(lambda x: x + 0.01 * torch.randn_like(x))], p=0.2),\n",
    "        ])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if (idx >= len(self.images) ):\n",
    "            image = self.images[idx % len(self.images)]\n",
    "            label = self.labels[idx % len(self.labels)]\n",
    "            image = image.to(torch.float32).div(255)\n",
    "            image = self.augmentation_transform(image)\n",
    "            image = image.mul(255).byte()\n",
    "            return image, torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        return image, torch.tensor(label, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regression_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(32400, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_2, self).__init__()\n",
    "\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # Batch normalization for improved training stability\n",
    "        self.batch_norm1 = nn.BatchNorm2d(64)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(128)\n",
    "        self.batch_norm3 = nn.BatchNorm2d(256)\n",
    "\n",
    "        # Max pooling layer\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "        # Dropout for regularization\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(256 * 24 * 24, 512)\n",
    "        self.fc2 = nn.Linear(512, 1)\n",
    "        self.sigmoid_layer = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.div(255).to(torch.float32)\n",
    "        x = self.pool(F.leaky_relu(self.batch_norm1(self.conv1(x))))\n",
    "        x = self.pool(F.leaky_relu(self.batch_norm2(self.conv2(x))))\n",
    "        x = self.pool(F.leaky_relu(self.batch_norm3(self.conv3(x))))\n",
    "\n",
    "        x = x.view(-1, 256 * 24 * 24)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to save the model\n",
    "def saveModel(model:nn.Module, path):\n",
    "    torch.save(model.state_dict(), path)\n",
    "\n",
    "# Training function. We simply have to loop over our data iterator and feed the inputs to the network and optimize.\n",
    "def train(model: torch.nn.Module,\n",
    "          dataloader: torch.utils.data.DataLoader,\n",
    "          valloader: torch.utils.data.DataLoader,\n",
    "          loss_fn: torch.nn.Module,\n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          metric: torchmetrics.Metric,\n",
    "          device: torch.device,\n",
    "          num_epochs,\n",
    "          path_model,\n",
    "          report: pd.DataFrame,\n",
    "          verbatim):\n",
    "    model.to(device)\n",
    "    metric.to(device)\n",
    "    best_accuracy = 0.0\n",
    "    best_loss = 0.0\n",
    "    best_epoch = 0\n",
    "    metric_algorithm = metric.__class__.__name__\n",
    "    loss_algorithm = loss_fn.__class__.__name__\n",
    "    best_metric = 100\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "        model.train()\n",
    "        metric.reset()\n",
    "        train_acc = 0.0\n",
    "        train_loss = 0.0\n",
    "        for ibatch, (images, labels) in enumerate(dataloader, 0):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(images)\n",
    "            y_pred = y_pred.squeeze(dim=1) # Output is [Batch size, 1], but we want [Batch size]\n",
    "            loss = loss_fn(y_pred, labels)\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            metric(y_pred, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Calculate and accumulate accuracy metric across all batches\n",
    "            #y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
    "            #train_acc += (y_pred_class == labels).sum().item()/len(y_pred)\n",
    "\n",
    "        # Adjust metrics to get average loss and accuracy per batch\n",
    "        train_loss = train_loss / len(dataloader)\n",
    "\n",
    "        # we want to save the model if the accuracy is the best\n",
    "\n",
    "        path = \"./myModel_\" +str(epoch)+ \".pth\"\n",
    "        #saveModel(model, path = path)\n",
    "\n",
    "        train_metric = metric.compute().item()/len(dataloader)\n",
    "        report_line = {'epoch': epoch,\n",
    "                       'loss': train_loss,\n",
    "                       'metric_algorithm': metric_algorithm,\n",
    "                       'metric': train_metric,\n",
    "                       'loss_algorithm': loss_algorithm,\n",
    "                       'mode': 'training'\n",
    "                      }\n",
    "        report = pd.concat([report, pd.DataFrame([report_line])], ignore_index=True)\n",
    "\n",
    "        if train_metric < best_metric:\n",
    "            path = str(path_model + '/bestModel.pth')\n",
    "            saveModel(model, path = path)\n",
    "            best_loss = train_loss\n",
    "            best_metric = train_metric\n",
    "            best_epoch = epoch\n",
    "            if verbatim:\n",
    "              print('Best Epoch #', epoch,' Loss=', best_loss, \" mean MAE(%)=\", train_metric)\n",
    "                \n",
    "        model.eval()\n",
    "        metric.reset()\n",
    "        val_loss = 0\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in valloader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                y_pred = model(images)\n",
    "                y_pred = y_pred.squeeze(dim=1) # Output is [Batch size, 1], but we want [Batch size]\n",
    "                val_loss += loss_fn(y_pred, labels).item()\n",
    "                metric(y_pred, labels)\n",
    "    \n",
    "        val_loss /= len(valloader)\n",
    "        val_metric = metric.compute().item()/len(valloader)\n",
    "        report_line = {'epoch': epoch,\n",
    "                       'loss': val_loss,\n",
    "                       'metric_algorithm': metric_algorithm,\n",
    "                       'metric': val_metric,\n",
    "                       'loss_algorithm': loss_algorithm,\n",
    "                       'mode': 'validation'\n",
    "                      }\n",
    "\n",
    "        print(val_metric)\n",
    "        report = pd.concat([report, pd.DataFrame([report_line])], ignore_index=True)\n",
    "    return best_loss, best_accuracy, best_epoch, report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SolarPanelDataset(train_df, images_dir, training=True)\n",
    "val_dataset = SolarPanelDataset(val_df, images_dir)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Epoch # 0  Loss= 344.83341161006194  mean MAE(%)= 0.3659149229995848\n",
      "0.7571873068809509\n",
      "Best Epoch # 1  Loss= 0.26652153219118363  mean MAE(%)= 0.06479607229157695\n",
      "1.0908008813858032\n"
     ]
    }
   ],
   "source": [
    "model = None\n",
    "gc.collect() # Python thing\n",
    "\n",
    "model = CNN_2()\n",
    "metric = torchmetrics.MeanAbsolutePercentageError()\n",
    "\n",
    "loss_fn = torch.nn.MSELoss().to(device)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=0.005, momentum=0.9)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "num_epochs = 2\n",
    "path_model = models_dir + f'/{model.__class__.__name__}_{loss_fn.__class__.__name__}'\n",
    "os.makedirs(path_model, exist_ok=True)\n",
    "report = pd.DataFrame()\n",
    "_, _, _, report = train(model, train_dataloader, val_dataloader, loss_fn, optimizer, metric, device, num_epochs, path_model, report, verbatim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='epoch', ylabel='metric'>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lineplot(data=report, x='epoch', y='metric', hue='mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to test the model with the test dataset and print the accuracy for the test images\n",
    "def test(model: torch.nn.Module,\n",
    "         dataloader: torch.utils.data.DataLoader,\n",
    "         loss_fn: torch.nn.Module,\n",
    "         metric: torchmetrics.Metric,\n",
    "         device: torch.device,\n",
    "         verbatim = True):\n",
    "\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    metric = metric.to(device)\n",
    "\n",
    "    # Setup test loss and test accuracy values\n",
    "    test_loss = 0\n",
    "    test_metric = 100\n",
    "    pred_labels = []\n",
    "    label_list = []\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            y_pred = model(images)\n",
    "            y_pred = y_pred.squeeze(dim=1) # Output is [Batch size, 1], but we want [Batch size]\n",
    "            pred_labels+=y_pred.tolist()\n",
    "            label_list += labels.tolist()\n",
    "            \n",
    "            loss = loss_fn(y_pred, labels)\n",
    "            test_loss += loss.item()\n",
    "            metric.update(y_pred, labels)\n",
    "\n",
    "    eval_df = pd.DataFrame({'labels': label_list, 'predictions': pred_labels})\n",
    "    # Adjust metrics to get average loss and accuracy per batch\n",
    "    test_loss = test_loss / len(dataloader)\n",
    "    test_metric = metric.compute()\n",
    "\n",
    "    if verbatim:\n",
    "      print(\"Loss =\", test_loss, f'  Metric ({metric.__class__.__name__})=', test_metric.item())\n",
    "    return pred_labels, test_loss, test_metric, eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.2967182440417154   Metric (MeanAbsolutePercentageError)= 1.0\n"
     ]
    }
   ],
   "source": [
    "metric = torchmetrics.MeanAbsolutePercentageError()\n",
    "test_dataset = SolarPanelDataset(test_df.sample(200), images_dir, augmentation_copies=0)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "_, _, _, eval_df = test(model, test_dataloader, loss_fn, metric, device, verbatim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.717600</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.070528</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.609511</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.636135</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.601414</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.413009</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.794698</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.612453</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.615898</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.002636</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       labels  predictions\n",
       "0    0.717600          0.0\n",
       "1    0.070528          0.0\n",
       "2    0.609511          0.0\n",
       "3    0.636135          0.0\n",
       "4    0.601414          0.0\n",
       "..        ...          ...\n",
       "195  0.413009          0.0\n",
       "196  0.794698          0.0\n",
       "197  0.612453          0.0\n",
       "198  0.615898          0.0\n",
       "199  0.002636          0.0\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df['diff'] = eval_df['labels'] - eval_df['predictions']\n",
    "eval_df['diff'] = eval_df['diff'].abs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "8rpJuShwm6wk"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_df.plot(kind='hist', y='diff', bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1vYUgNJypt8t"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
